# Root Coda: The Visual Monolith (v2.1)

**Status:** Production | **Philosophy:** 100% Local, 100% Browser, 100% Sovereign.

## 1. The Kernel (System Architecture)
The **Sovereign Kernel** (`sovereign.js`) abstracts hardware, manages state, and enforces the "Consciousness Semaphore" (Resource Hardening).

```mermaid
graph TD
    User[User Input] --> Kernel[Sovereign Kernel]
    Kernel -->|State: LISTENING| Mic[Root Mic]
    Kernel -->|State: COGNITION| Console[Root Console]
    Kernel -->|State: DREAMING| Dreamer[Root Dreamer]
    
    subgraph Hardware Layer
        Kernel -->|Clamp Buffer| WebGPU[WebGPU Adapter]
        Kernel -->|Persist| IDB[IndexedDB]
    end
    
    Console -.->|Block| Dreamer
    Mic -.->|Block| Dreamer
```

**Key Components:**
- **Hardware Abstraction:** Clamps WebGPU buffers (256MB/1GB) for Snapdragon/Mobile stability.
- **Consciousness Semaphore:** Ensures `Dreamer` (background tasks) yields instantly to `Console` or `Mic` (active tasks) to prevent VRAM crashes.
- **Unified Logger:** Broadcasts logs to `log-viewer.html` via `BroadcastChannel`.

---

## 2. The Memory (CozoDB + WASM)
A Hybrid Graph-Vector database running entirely in WASM, persisted to IndexedDB/OPFS.

```mermaid
erDiagram
    MEMORY {
        string id PK
        int timestamp
        string role
        string content
        string source
        vector embedding
    }
    RELATIONSHIPS {
        string source_id FK
        string target_id FK
        string type
        float weight
    }
    MEMORY ||--o{ RELATIONSHIPS : connects_to
```

**Schema:**
- **`*memory`**: Stores raw text, chat logs, and vector embeddings (`<F32; 384>`).
- **`*relationships`**: Stores synaptic links generated by the Dreamer (Subconscious).
- **Persistence:** Writes to WASM memory, auto-flushes to `coda_memory` (IndexedDB).

---

## 3. The Logic (Graph-R1 Loop)
The reasoning engine combining Semantic Search (Vector) and Lexical Search (Keyword) with a self-correcting LLM loop.

```mermaid
stateDiagram-v2
    [*] --> Reflex: User Query
    Reflex --> ContextManager: Top-k Vectors + Keywords
    ContextManager --> LLM: Virtual Prompt
    LLM --> Synthesis: Answer Found
    LLM --> Reflex: NEED_CONTEXT (Tool Call)
    Synthesis --> [*]: Stream Response
```

**Flow:**
1. **Reflex:** Simultaneous Vector + Regex search.
2. **Context Manager:** Assembles "Virtual Prompt" with retrieved clues + System Time.
3. **Loop:** LLM generates answer or requests more data (`NEED_CONTEXT:`).

---

## 4. The Bridge (Silent Injection)
Extensions allow the Sovereign Brain to inject context into corporate LLMs (Gemini/ChatGPT).

```mermaid
sequenceDiagram
    participant Chrome as Chrome Extension
    participant Bridge as WebGPU Bridge (ws:8080)
    participant DB as CozoDB (WASM)
    
    Chrome->>Chrome: User types... (3s pause)
    Chrome->>Bridge: queryMemories(text)
    Bridge->>DB: Run Datalog Query
    DB-->>Bridge: JSON Result
    Bridge-->>Chrome: Context Summary
    Chrome->>Chrome: Inject into Textarea
```

**Security:**
- **Local-First:** No data leaves localhost.
- **Obfuscation:** Binds to random port or 8080.
- **Protocol:** WebSocket for low-latency (<50ms) lookup.
